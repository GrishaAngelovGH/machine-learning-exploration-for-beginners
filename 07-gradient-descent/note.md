## 7. **Градиентно спускане (Gradient Descent)**:

**Описание**: Оптимизационен алгоритъм, използван за минимизиране на функция на разходите и намиране на оптималните параметри на модела. Gradient Descent е итеративен алгоритъм, използван за оптимизиране на функции. Основната му цел е да минимизира грешката или загубата на дадена функция, като последователно коригира параметрите в посока на най-голямото намаление на градиента (наклона) на функцията. Алгоритъмът започва с произволни параметри и прави малки стъпки в посока на обратна на градиента, докато не достигне локален или глобален минимум. Това е основен метод в машинното обучение за обучение на модели и намиране на оптималните им параметри.

**Пример**: Да си представим, че тренираме модел за прогнозиране на разходите за отопление въз основа на броя на стаите в къщата. Започваме с произволни стойности за параметрите на модела. Gradient Descent изчислява градиента на функцията на загуба, която измерва разликата между прогнозните и реалните разходи. След това алгоритъмът прави малки корекции в параметрите в посока на обратна на градиента, за да намали загубата. Този процес се повтаря, докато параметрите не достигнат стойности, които минимизират функцията на загуба, което означава, че моделът е оптимално настроен за прогнозиране на разходите за отопление.